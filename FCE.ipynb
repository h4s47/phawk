{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40645c8-253b-4abf-8301-78d91abbbda6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install labelme tensorflow opencv-python matplotlib albumentations numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edeb5f-9c0d-4dc7-847c-275463acc2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "ImgPath = os.path.join('Data', 'CollectedImages')\n",
    "no_img = 1\n",
    "Lcap = cv2.VideoCapture(0)  # captures feed from cam, camera configured as \"0\"\n",
    "Lcap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', '4', 'v'))  # video codec for good video feed\n",
    "Lcap.set(3, 900)  # video resolution\n",
    "Lcap.set(4, 600)\n",
    "for Img_no in range(no_img):\n",
    "    print('capturing image(s) {}'.format(Img_no))\n",
    "    Img_id = os.path.join(ImgPath, f'{str(uuid.uuid1())}.jpg')\n",
    "    ret, frame = Lcap.read()\n",
    "    cv2.imwrite(Img_id, frame)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    key = cv2.waitKey(10)  # ms waittime for closing window\n",
    "    if key == 27:  # key 'esc' for closing camera feed\n",
    "        break\n",
    "Lcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07362ba1-b0f3-468f-89cf-9d4d60cf7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fc132-25cd-4149-ae19-c03c15964f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0150c-4f81-4e7d-bfe0-dfd5d1bd9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42379cce-0d09-4168-9414-3dbbbfb43448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fee6c-5d58-4b47-9401-3b070c390480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94645816-6179-4b0a-80ee-7e7c359d455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img = tf.data.Dataset.list_files('Data\\\\CollectedImages\\\\*.jpg', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28caa538-8893-4bf8-a2cb-13de5729e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead9e4d-2d79-4ef7-9f16-76bc6c0edd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDAImg(x): \n",
    "    encImg = tf.io.read_file(x)\n",
    "    dImg = tf.io.decode_jpeg(encImg)\n",
    "    return dImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4920040-a9d8-4a08-81ed-3444efd8b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Img = Img.map(LDAImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fd97d-218c-4dc4-a084-ee647aa2eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Img.as_numpy_iterator().next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028ff24-5930-439d-91b6-fd2c5e8aede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b8b050-9d3b-4704-9a09-b337ed31d26a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye\n"
     ]
    }
   ],
   "source": [
    "#Img = tf.data.Dataset.list_files('Data\\\\CollectedImages\\\\*.jpg',shuffle=False)\n",
    "#print(Img.as_numpy_iterator().next())\n",
    "\n",
    "#def LDAImg(x):\n",
    " #   encImg = tf.io.read_file(x)\n",
    "  #  dImg = tf.io.decode_jpeg(encImg)\n",
    "   # return dImg\n",
    "#Img = Img.map(LDAImg)\n",
    "#print(Img.as_numpy_iterator().next())\n",
    "#print(type(Img))\n",
    "print(\"ye\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0630243-1aee-4a43-852f-810e9274e524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ImgGen = Img.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07a66d-14f5-4b6e-94d3-af79306cd6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pImg = ImgGen.next()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(pImg):\n",
    "    ax[idx].imshow(image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de478a52-b7dc-4194-944d-4d3fc1ac9c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in ['Test','Train','Validation']:\n",
    "    for file in os.listdir(os.path.join('Data',folder,'CollectedImages')):\n",
    "        FName = file.split('.')[0]+'.csv'\n",
    "        ExFPath = os.path.join('Data','Labels',FName)\n",
    "        if os.path.exists(ExFPath):\n",
    "            NFPath = os.path.join('Data',folder,'Labels',FName)\n",
    "            os.replace(ExFPath, NFPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27538df-e56f-4dd6-95e8-977bf5a049ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb672cb-1de6-4e50-9a0c-99dcc550742e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fd1c4-9171-493b-b083-050269e04b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dImg = cv2.imread(os.path.join('Data','Train','CollectedImages','7683b27d-d628-11ed-a79f-ebebb2e11f69.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b4f02-c25a-4996-b6c6-67c1d176dc66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a21f5c-e52f-498d-aeb0-b228883add7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('Data','Train','Labels','7683b27d-d628-11ed-a79f-ebebb2e11f69.json'), 'r') as f:\n",
    "    LImg = list(csv.reader(f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbcc47e-a159-435a-ab41-ac6101681e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LImg['shapes'][0]['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b21b97-e7a6-4489-80d4-49144a59d268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Coords = [0,0,0,0]\n",
    "\n",
    "Coords[0] = LImg['shapes'][0]['points'][0][0]\n",
    "Coords[1] = LImg['shapes'][0]['points'][0][1]\n",
    "Coords[2] = LImg['shapes'][0]['points'][1][0]\n",
    "Coords[3] = LImg['shapes'][0]['points'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f471cf6-55be-44b3-be10-2aa7cddd6e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2701e4-b528-4235-836d-6a9d790cf684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Coords = list(np.divide(Coords, [800,600,800,600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d4dbf-610e-4d46-b1ae-ae648dc02f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c58c6-fa6e-446c-a8bf-cc58f0825ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented = augmentor(image=dImg, bboxes=[Coords], class_labels=['Face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4137affd-a62d-47ac-b54b-ae6f26eb695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "print(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a9487-e401-4825-b1a6-8b64246a7c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff3e2c-12f9-4622-b83f-06280c7467ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d878a-1015-4164-a983-1b6f1d9e8752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.rectangle(augmented['image'], \n",
    "              tuple(np.multiply(augmented['bboxes'][0][:2], [450,450]).astype(int)),\n",
    "              tuple(np.multiply(augmented['bboxes'][0][2:], [450,450]).astype(int)), \n",
    "                    (255,0,0), 2)\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5336292-ed8e-4327-89a6-6ddf11ab7fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ee05a-91bc-4fbc-b714-e7a0a5215097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for partition in ['Train','Test','Validation']: \n",
    "    for image in os.listdir(os.path.join('Data', partition, 'CollectedImages')):\n",
    "        dImg = cv2.imread(os.path.join('Data', partition, 'CollectedImages', image))\n",
    "\n",
    "        Coords = [0,0,0.00001,0.00001]\n",
    "        LPath = os.path.join('Data', partition, 'Labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(LPath):\n",
    "            with open(LPath, 'r') as f:\n",
    "                LImg = json.load(f)\n",
    "\n",
    "            Coords[0] = LImg['shapes'][0]['points'][0][0]\n",
    "            Coords[1] = LImg['shapes'][0]['points'][0][1]\n",
    "            Coords[2] = LImg['shapes'][0]['points'][1][0]\n",
    "            Coords[3] = LImg['shapes'][0]['points'][1][1]\n",
    "            Coords = list(np.divide(Coords, [800,600,800,600]))\n",
    "\n",
    "        try: \n",
    "            for x in range(150):\n",
    "                augmented = augmentor(image=dImg, bboxes=[Coords], class_labels=['Face'])\n",
    "                cv2.imwrite(os.path.join('AugData', partition, 'CollectedImages', f'{image.split(\".\")[0]}.{x}.jpg'), augmented['image'])\n",
    "\n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "                if os.path.exists(LPath):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                with open(os.path.join('AugData', partition, 'Labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f7ffb-ee05-4086-a619-1cdd2aa983ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImg = tf.data.Dataset.list_files('AugData\\\\Train\\\\CollectedImages\\\\*.jpg', shuffle=False)\n",
    "TrainImg = TrainImg.map(LDAImg)\n",
    "TrainImg = TrainImg.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "TrainImg = TrainImg.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4573e10-103c-4aa2-9e70-1bb813dad30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestImg = tf.data.Dataset.list_files('AugData\\\\Test\\\\CollectedImages\\\\*.jpg', shuffle=False)\n",
    "TestImg = TestImg.map(LDAImg)\n",
    "TestImg = TestImg.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "TestImg = TestImg.map(lambda x: x/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93aee8f-f09f-4782-ac10-1bc31ba124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationImg = tf.data.Dataset.list_files('AugData\\\\Validation\\\\CollectedImages\\\\*.jpg', shuffle=False)\n",
    "ValidationImg = ValidationImg.map(LDAImg)\n",
    "ValidationImg = ValidationImg.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "ValidationImg = ValidationImg.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74ff47-752e-4f67-96e5-8477d056d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImg.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdc475-3a08-42da-9d09-6f7707772195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf335d-84b9-48c9-8334-56280039560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(LPath):\n",
    "    with open(LPath.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        LImg = json.load(f)\n",
    "        \n",
    "    return [LImg['class']], LImg['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d353-1baf-4ec1-95b0-e3a0d42d27f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576c831-fffb-425e-8fee-00d5e8c9d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLabels = tf.data.Dataset.list_files('AugData\\\\Train\\\\Labels\\\\*.json', shuffle=False)\n",
    "TrainLabels = TrainLabels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f33f2-9a2a-406e-ad75-d334bc0d5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestLabels = tf.data.Dataset.list_files('AugData\\\\Test\\\\Labels\\\\*.json', shuffle=False)\n",
    "TestLabels = TestLabels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c041e5a-135e-4e09-a622-15e7a0a0a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationLabels = tf.data.Dataset.list_files('AugData\\\\Validation\\\\Labels\\\\*.json', shuffle=False)\n",
    "ValidationLabels = ValidationLabels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9b23c-ef52-4ce9-b441-d24c3a84729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationLabels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c467c727-a859-4223-82d0-b73d07eb51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TrainImg),len(TrainLabels),len(TestImg),len(TestLabels),len(ValidationImg),len(ValidationLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd4f11-53a2-467c-8e79-47220f09183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = tf.data.Dataset.zip((TrainImg, TrainLabels))\n",
    "Train = Train.shuffle(17000)\n",
    "Train = Train.batch(8)\n",
    "Train = Train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a5a53-1934-46fe-b52f-9e7388d70831",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = tf.data.Dataset.zip((TestImg, TestLabels))\n",
    "Test = Test.shuffle(5000)\n",
    "Test = Test.batch(8)\n",
    "Test = Test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47575c-c9f1-4216-9497-1cb1ce966990",
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation = tf.data.Dataset.zip((ValidationImg, ValidationLabels))\n",
    "Validation = Validation.shuffle(5000)\n",
    "Validation = Validation.batch(8)\n",
    "Validation = Validation.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576b8d7-445f-46fa-ba6a-dfbf4beaf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.as_numpy_iterator().next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd542d8-c530-45fe-8d04-d01e3a427ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSamp = Train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f674b7d-afe9-4c09-a2db-48f059809955",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = DSamp.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2464df9d-cb45-401e-9ab6-54b5ed3b462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    SampImg = res[0][idx]\n",
    "    Sampcoords = res[1][1][idx]\n",
    "    \n",
    "    cv2.rectangle(SampImg, \n",
    "                  tuple(np.multiply(Sampcoords[:2], [120,120]).astype(int)),\n",
    "                  tuple(np.multiply(Sampcoords[2:], [120,120]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "\n",
    "    ax[idx].imshow(SampImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527185e-5249-4730-8c23-c945f26fba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8a44f-ed0d-4cd5-94f3-69817226e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG = VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20227e7-b044-42d5-bfa3-63786f78d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b910f-2514-4f56-8bd7-181c2cd144b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    ILayer = Input(shape=(120,120,3))\n",
    "    \n",
    "    VGG = VGG16(include_top=False)(ILayer)\n",
    "\n",
    "    \n",
    "    f1 = GlobalMaxPooling2D()(VGG)\n",
    "    class1 = Dense(2048, activation='relu')(f1)\n",
    "    class2 = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    \n",
    "    f2 = GlobalMaxPooling2D()(VGG)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    Facetracker = Model(inputs=ILayer, outputs=[class2, regress2])\n",
    "    return Facetracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9156cd-d3d3-4e12-ba2e-72b4226b149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Facetracker = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd84df2-2c69-44f3-bab6-58b9938b6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "Facetracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16787fa4-ae49-4014-b850-a11eac971167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02088f7-0fca-47a1-8f11-8863ff3d6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf8f99-c3c1-40c9-88d4-507b4f19f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, Coords = Facetracker.predict(X)#kerenel crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08d517-628f-4f92-8036-a184f606a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407c479-c73c-4030-9e65-17ba8a28d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1a282-1c98-4a2a-b5de-4b00770e7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(Train)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4b1b9-254f-47a5-8ded-0da549eacee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972fa5c-8c7e-4782-8fa6-b5a4441196ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ca671-f1f8-40eb-910a-cd7f6667cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):            \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2]))\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] \n",
    "    w_true = y_true[:,2] - y_true[:,0] \n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    \n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    \n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f428e61-42ab-4e42-856b-f42f6d83df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss = localization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f49b3-5707-42ea-8457-985ab23249f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_loss(y[1], Coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd12bb-05d5-4acd-ac88-a24ab66a283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss(y[0], classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbb7b3-006a-4bf2-8759-931035e96690",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressloss(y[1], Coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57cb06-ca31-467d-8a2b-6118abbcb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTracker(Model): \n",
    "    def __init__(self, Facetracker,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = Facetracker\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "    \n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, Coords = self.model(X, training=True)\n",
    "            \n",
    "            batch_classloss = self.closs(y[0], classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), Coords)\n",
    "            \n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes, Coords = self.model(X, training=False)\n",
    "        \n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), Coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921cea4c-0586-4cfb-b4d5-9c741a486036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceTracker(Facetracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d55e4b-e957-4970-b209-5a78a31afb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f566828-ef32-4f4d-a9bf-05674f44239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e10e7-8945-4d67-9cca-0a4c5b89411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d5c8bd-8eaf-48af-b96b-11b655eced82",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(Train, epochs=20, validation_data=Validation, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31259efd-563f-40ef-80d7-c08184507a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6bdf6-ab0e-43e2-ab19-22433a779173",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
    "ax[0].plot(hist.history['val_total_loss'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
    "ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
    "ax[1].title.set_text('Classification Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
    "ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
    "ax[2].title.set_text('Regression Loss')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674db5f4-969b-406e-b8cc-206769947a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c86012-9e13-4c43-ab69-bf1a4cce8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18e63d-b47c-4d0c-b602-5f9dd8f6b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = Facetracker.predict(test_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac445d1e-ffe8-45fd-a8bb-28037454bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx]\n",
    "    Sampcoords = yhat[1][idx]\n",
    "    \n",
    "    if yhat[0][idx] > 0.9:\n",
    "        cv2.rectangle(sample_image, \n",
    "                      tuple(np.multiply(Sampcoords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(Sampcoords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7eb2f-dbf5-4f96-9114-b4915c11fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef51fa-bd91-4a21-b831-5b5bb54b6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facetracker.save('Facetrackerv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43590b-6db8-4adf-85d7-ffa327ee613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker = load_model('facetrackerv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286fc863-9189-41ce-95c7-7cd6195550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcap = cv2.VideoCapture(0)\n",
    "while Lcap.isOpened():\n",
    "    _ , frame = Lcap.read()\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    yhat = Facetracker.predict(np.expand_dims(resized/255,0))\n",
    "    Sampcoords = yhat[1][0]\n",
    "    \n",
    "    if yhat[0] > 0.5: \n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(Sampcoords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(Sampcoords[2:], [450,450]).astype(int)), \n",
    "                            (255,202,90), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(Sampcoords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(Sampcoords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,202,90), -1)\n",
    "        \n",
    "        # Controls the text rendered\n",
    "        cv2.putText(frame, 'Face', tuple(np.add(np.multiply(Sampcoords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('FaceTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "Lcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65f13e-a643-466c-8cc0-46410b0ff646",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FCEvirtenv",
   "language": "python",
   "name": "fcevirtenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
